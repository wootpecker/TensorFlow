{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Erstellung eines Bildklassifikators auf Basis des CIFAR-10 Dataset mit Keras (TensorFlow 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variablen für das Training\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für die 10 Klassen von CIFAR-10\n",
    "CIFAR_10_CLASSES = [\"Flugzeug\",\"Auto\",\"Vogel\",\"Katze\",\"Hirsch\",\"Hund\", \"Frosch\", \"Pferd\",\"Boot\",\"LKW\"]\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir laden den Datenset über Keras\n",
    "(images_train, labels_train), (images_test, labels_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "plt.title(CIFAR_10_CLASSES[int(labels_train[25])])\n",
    "plt.imshow(images_train[25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = np.array(images_train,dtype=\"float32\")\n",
    "images_test = np.array(images_test,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train /= 255 # Damit die Werte zwischen 0 und 1 bleiben\n",
    "images_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = to_categorical(labels_train, NUM_CLASSES)\n",
    "labels_test = to_categorical(labels_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel von einer Subclassing eines Keras-Modells\n",
    "class MyCIFARModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyCIFARModel, self).__init__()\n",
    "        self.conv_1 = Conv2D(32, (3, 3), padding='same',input_shape=(32, 32, 3),activation=\"relu\")\n",
    "        self.max_pool_1 = MaxPool2D(pool_size=(2,2))\n",
    "        self.conv_2 = Conv2D(64, (3, 3), padding='same')\n",
    "        self.max_pool_2 = MaxPool2D(pool_size=(2,2))\n",
    "        self.conv_3 = Conv2D(64, (3, 3), padding='same')\n",
    "        self.max_pool_3 = MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(512,activation=\"relu\")\n",
    "        self.softmax = Dense(10,activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.max_pool_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.max_pool_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.max_pool_3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante 1: Definition des Modells mit Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Variante 1 mit Sequential === \n"
     ]
    }
   ],
   "source": [
    "print(\"=== Variante 1 mit Sequential === \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=(32, 32, 3),activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(NUM_CLASSES,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 49s 979us/sample - loss: 2.3065 - accuracy: 0.0944\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 49s 977us/sample - loss: 2.2825 - accuracy: 0.1559\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 49s 988us/sample - loss: 2.2649 - accuracy: 0.1834\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 59s 1ms/sample - loss: 2.2477 - accuracy: 0.2142\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 62s 1ms/sample - loss: 2.2286 - accuracy: 0.2349\n",
      "Epoch 6/50\n",
      " 1216/50000 [..............................] - ETA: 1:01 - loss: 2.2218 - accuracy: 0.2525"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics = [\"accuracy\"])\n",
    "model.fit(images_train,labels_train, batch_size=BATCH_SIZE,epochs=EPOCHS)\n",
    "scores = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loss:', scores[0])\n",
    "print('Accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model,\"cifar_model_sequential\")\n",
    "model.save(\"cifar_model.h5\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variante 2\n",
    "print(\"=== Variante 2 mit Model-Subclassing === \")\n",
    "model = MyCIFARModel()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics = [\"accuracy\"])\n",
    "model.fit(images_train,labels_train, batch_size=BATCH_SIZE,epochs=EPOCHS)\n",
    "scores = model.evaluate(images_test,labels_test)\n",
    "print('Loss:', scores[0])\n",
    "print('Accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir speichern das Model mit tf.saved_model\n",
    "model.save('cifar_model_subclassing', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugt aktuell eine Fehlermeldung, wenn Modell-Subclassing\n",
    "# model.save(\"cifar_model_subclassing.h5\") \n",
    "# Lösung:\n",
    "model.save_weights(\"cifar_model_subclassing_weights\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus dem Google Colab von\n",
    "# Francois Chollet:\n",
    "# https://colab.research.google.com/drive/172D4jishSgE3N7AO6U2OKAA_0wNnrMOq#scrollTo=gMg87Tz01cxQ\n",
    "my_new_model = MyCIFARModel()\n",
    "my_new_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics = [\"accuracy\"])\n",
    "my_new_model.load_weights(\"cifar_model_subclassing_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_new_model.predict(images_train[25].reshape(-1, 32, 32, 3))\n",
    "index_max_predictions = np.argmax(predictions)\n",
    "print(\"Ergebnis: {}\".format(CIFAR_10_CLASSES[index_max_predictions]))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
